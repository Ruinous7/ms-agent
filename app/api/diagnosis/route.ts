import OpenAI from 'openai';
import { createClient } from '@/utils/supabase/server';
import { NextResponse } from 'next/server';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface DiagnosisResponse {
  question: { text: string };
  option: { display: string; he_value: string };
}

// Set maxDuration to 60 seconds (maximum allowed for hobby plan)
export const config = {
  maxDuration: 60,
  // Add runtime configuration for Edge runtime to improve performance
  runtime: 'edge'
};

export async function POST(request: Request) {
  try {
    const supabase = await createClient();
    
    // Check authentication
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    // Fetch user's responses with questions and answers
    const { data: responses } = await supabase
      .from('responses')
      .select(`
        question:questions(text),
        option:options(display, he_value)
      `)
      .eq('user_id', user.id)
      .order('created_at') as { data: DiagnosisResponse[] | null };

    if (!responses?.length) {
      return NextResponse.json(
        { error: 'No questionnaire responses found' },
        { status: 404 }
      );
    }

    // Format responses for OpenAI - optimize by pre-allocating array size
    const formattedResponses = new Array(responses.length);
    for (let i = 0; i < responses.length; i++) {
      const r = responses[i];
      formattedResponses[i] = `Question: ${r.question.text}\nAnswer: ${r.option.he_value || r.option.display}`;
    }
    const formattedResponsesText = formattedResponses.join('\n\n');

    // Get diagnosis from OpenAI with optimized settings
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: "×ž×˜×¨×ª×š: ×¢×œ ×‘×¡×™×¡ ×ª×©×•×‘×•×ª ××œ×•, × ×ª×— ××ª ×ž×¦×‘ ×”×¢×¡×§, ×–×™×”×” ××ª×’×¨×™× ×¢×™×§×¨×™×™×, ×•×”×¦×’ 3 ×¤×¢×•×œ×•×ª ×¤×¨×§×˜×™×•×ª ×œ×©×™×¤×•×¨.\n\nðŸ“Œ ×ž×‘× ×” ×”×ª×©×•×‘×” ×”×¨×¦×•×™:\n1. **×¡×™×›×•× ×§×¦×¨ ×©×œ ×ž×¦×‘ ×”×¢×¡×§** (×ž×§×¡×™×ž×•× 3 ×ž×©×¤×˜×™×).\n2. **×–×™×”×•×™ 2-3 ×‘×¢×™×•×ª ×¢×™×§×¨×™×•×ª ×‘×¢×¡×§** (×œ×¤×™ ×”×ž×™×“×¢ ×©×¡×™×¤×§ ×”×ž×©×ª×ž×©).\n3. **×¨×©×™×ž×” ×©×œ 3 ×¦×¢×“×™× ×‘×¨×•×¨×™× ×•×ž×¢×©×™×™× ×œ×¤×¢×•×œ×”** ×©×™×¡×™×™×¢×• ×œ×ž×©×ª×ž×© ×œ×©×¤×¨ ××ª ×”×¢×¡×§ ×©×œ×•.\n\nâ— *×—×©×•×‘*: ×”×ª×©×•×‘×” ×—×™×™×‘×ª ×œ×”×™×•×ª ×‘×¢×‘×¨×™×ª, ×‘×¨×•×¨×” ×•×ž×¢×©×™×ª."
        },
        {
          role: "user",
          content: `×× × × ×ª×— ××ª ×”×ª×©×•×‘×•×ª ×œ×©××œ×•×Ÿ ×”×¢×¡×§×™ ×”×‘× ×•×¡×¤×§ ××‘×—×•×Ÿ ×ž×¤×•×¨×˜:\n\n${formattedResponsesText}`
        }
      ],
      max_tokens: 800,  // Reduced token limit to speed up response
      temperature: 0.7,
    });

    const aiDiagnosis = completion.choices[0].message.content;

    // Update profile with diagnosis - single database operation
    const { error: updateError } = await supabase
      .from('profiles')
      .upsert({ 
        id: user.id,
        business_diagnosis: aiDiagnosis,
        updated_at: new Date().toISOString(),
        created_at: new Date().toISOString()
      }, {
        onConflict: 'id'
      });

    if (updateError) {
      console.error('Error saving diagnosis:', updateError);
      throw updateError;
    }

    return NextResponse.json({
      diagnosis: aiDiagnosis
    });

  } catch (error) {
    console.error('Diagnosis error:', error);
    return NextResponse.json(
      { error: 'Failed to generate diagnosis' },
      { status: 500 }
    );
  }
} 